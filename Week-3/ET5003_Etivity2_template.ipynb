{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "930vlW5BrOtq"
   },
   "source": [
    "<div>\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1vK33e_EqaHgBHcbRV_m38hx6IkG0blK_\" width=\"350\"/>\n",
    "</div> \n",
    "\n",
    "#**Artificial Intelligence - MSc**\n",
    "##ET5003 - MACHINE LEARNING APPLICATIONS \n",
    "\n",
    "###Instructor: Enrique Naredo\n",
    "###ET5003_Etivity-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "LqXD_IwUQuBF"
   },
   "outputs": [],
   "source": [
    "#@title Current Date\n",
    "Today = '2021-09-25' #@param {type:\"date\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "uzDKau31OjVO"
   },
   "outputs": [],
   "source": [
    "#@markdown ---\n",
    "#@markdown ### Enter your details here:\n",
    "Student_ID = \"19137338\" #@param {type:\"string\"}\n",
    "Student_full_name = \"Rana Das\" #@param {type:\"string\"}\n",
    "#@markdown ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "r39xGZckTpKx"
   },
   "outputs": [],
   "source": [
    "#@title Notebook information\n",
    "Notebook_type = 'Etivity' #@param [\"Example\", \"Lab\", \"Practice\", \"Etivity\", \"Assignment\", \"Exam\"]\n",
    "Version = 'Draft' #@param [\"Draft\", \"Final\"] {type:\"raw\"}\n",
    "Submission = False #@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_A0Z6S-r6DpA"
   },
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkRchZtf6IV-"
   },
   "source": [
    "**Piecewise regression**, extract from [Wikipedia](https://en.wikipedia.org/wiki/Segmented_regression):\n",
    "\n",
    "Segmented regression, also known as piecewise regression or broken-stick regression, is a method in regression analysis in which the independent variable is partitioned into intervals and a separate line segment is fit to each interval. \n",
    "\n",
    "* Segmented regression analysis can also be performed on \n",
    "multivariate data by partitioning the various independent variables. \n",
    "* Segmented regression is useful when the independent variables, clustered into different groups, exhibit different relationships between the variables in these regions. \n",
    "\n",
    "* The boundaries between the segments are breakpoints.\n",
    "\n",
    "* Segmented linear regression is segmented regression whereby the relations in the intervals are obtained by linear regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aajlS0WCJ8pm"
   },
   "source": [
    "***The goal is to use advanced Machine Learning methods to predict House price.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wg7VCbX77eAA"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iFFLThrpwibd"
   },
   "outputs": [],
   "source": [
    "# Suppressing Warnings:\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1770_fNrCWn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYPJU_Y6O6Dq"
   },
   "outputs": [],
   "source": [
    "# to plot\n",
    "import matplotlib.colors\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# to generate classification, regression and clustering datasets\n",
    "import sklearn.datasets as dt\n",
    "\n",
    "# to create data frames\n",
    "from pandas import DataFrame\n",
    "\n",
    "# to generate data from an existing dataset\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MUJdlxSPSMM"
   },
   "outputs": [],
   "source": [
    "# Define the seed so that results can be reproduced\n",
    "seed = 11\n",
    "rand_state = 11\n",
    "\n",
    "# Define the color maps for plots\n",
    "color_map = plt.cm.get_cmap('RdYlBu')\n",
    "color_map_discrete = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"cyan\",\"magenta\",\"blue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WL91ShB19RPw"
   },
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESg5DGKWJSOf"
   },
   "source": [
    "Extract from this [paper](https://ieeexplore.ieee.org/document/9300074):\n",
    "\n",
    "* House prices are a significant impression of the economy, and its value ranges are of great concerns for the clients and property dealers. \n",
    "\n",
    "* Housing price escalate every year that eventually reinforced the need of strategy or technique that could predict house prices in future. \n",
    "\n",
    "* There are certain factors that influence house prices including physical conditions, locations, number of bedrooms and others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8Y2pf50FlYL"
   },
   "source": [
    "1. [Download the dataset](https://github.com/UL-ET5003/ET5003_SEM1_2021-2/tree/main/Week-3). \n",
    "\n",
    "2. Upload the dataset into your folder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMkdCQEmKTof"
   },
   "source": [
    "The challenge is to predict the final price of each house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PMoPLlUJ1Ly"
   },
   "source": [
    "## Training & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loLTHklwKGnV"
   },
   "outputs": [],
   "source": [
    "# split data into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# training: 70% (0.7), test: 30% (0.3) \n",
    "# you could try any other combination \n",
    "# but consider 50% of training as the low boundary\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztBkSZluye87"
   },
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rosmH4665uJ"
   },
   "outputs": [],
   "source": [
    "# training dataset: \n",
    "training_file = syntPath+filename1\n",
    "# test dataset: \n",
    "testing_file = syntPath+filename2\n",
    "# cost dataset: \n",
    "cost_file = syntPath+filename3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XUFUPABMHfF"
   },
   "outputs": [],
   "source": [
    "# show first data frame rows \n",
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rq_p-D4yLBe"
   },
   "outputs": [],
   "source": [
    "# Generate descriptive statistics\n",
    "dftrain.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iqg9_uxFyZli"
   },
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bw2_yypxMfsi"
   },
   "outputs": [],
   "source": [
    "# show first data frame rows \n",
    "dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXo0x2u7T7-1"
   },
   "outputs": [],
   "source": [
    "# Generate descriptive statistics\n",
    "dftest.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjMH1CSEUA1A"
   },
   "source": [
    "### Expected Cost dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7p63sCZeUNx3"
   },
   "outputs": [],
   "source": [
    "# Generate descriptive statistics\n",
    "dfcost.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJFJQxAS9HZK"
   },
   "source": [
    "# PIECEWISE REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQ_1QsLToIDi"
   },
   "source": [
    "## Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yv5j1KzzMUnm"
   },
   "outputs": [],
   "source": [
    "# select some features columns just for the baseline model\n",
    "# assume not all of the features are informative or useful\n",
    "# in this exercise you could try all of them if possible\n",
    "\n",
    "featrain = ['feature_1','feature_2','feature_3','cost']\n",
    "# dropna: remove missing values\n",
    "df_subset_train = dftrain[featrain].dropna(axis=0)\n",
    "\n",
    "featest = ['feature_1','feature_2','feature_3']\n",
    "df_subset_test  =  dftest[featest].dropna(axis=0)\n",
    "\n",
    "# cost\n",
    "df_cost = df_cost[df_cost.index.isin(df_subset_test.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZK2kfygoIDi"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "with pm.Model() as model:\n",
    "    #prior over the parameters of linear regression\n",
    "    alpha = pm.Normal('alpha', mu=0, sigma=30)\n",
    "    #we have one beta for each column of Xn\n",
    "    beta = pm.Normal('beta', mu=0, sigma=30, shape=Xn_train.shape[1])\n",
    "    #prior over the variance of the noise\n",
    "    sigma = pm.HalfCauchy('sigma_n', 5)\n",
    "    #linear regression model in matrix form\n",
    "    mu = alpha + pm.math.dot(beta, Xn_train.T)\n",
    "    #likelihood, be sure that observed is a 1d vector\n",
    "    like = pm.Normal('like', mu=mu, sigma=sigma, observed=yn_train[:,0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIskuS3ToIDk"
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "ll=np.mean(posterior['alpha']) + np.dot(np.mean(posterior['beta'],axis=0), Xn_test.T)\n",
    "y_pred_BLR = np.exp(yscaler.inverse_transform(ll.reshape(-1,1)))[:,0]\n",
    "print(\"MAE = \",(np.mean(abs(y_pred_BLR - y_test))))\n",
    "print(\"MAPE = \",(np.mean(abs(y_pred_BLR - y_test) / y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_jBBKvtoIDk"
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYFvbgYDaEOS"
   },
   "source": [
    "### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iphQ53UE0iVw"
   },
   "outputs": [],
   "source": [
    "# training gaussian mixture model \n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h51OhBV5Z4tY"
   },
   "source": [
    "### Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNvx_KxrLt90"
   },
   "outputs": [],
   "source": [
    "# train clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wTT4220zFNx"
   },
   "outputs": [],
   "source": [
    "# test clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXF25ZDYoIDl"
   },
   "source": [
    "## Piecewise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1e-4ruvaJci"
   },
   "outputs": [],
   "source": [
    "# model_0\n",
    "with pm.Model() as model_0:\n",
    "  # prior over the parameters of linear regression\n",
    "  alpha = pm.Normal('alpha', mu=0, sigma=30)\n",
    "  # we have a beta for each column of Xn0\n",
    "  beta = pm.Normal('beta', mu=0, sigma=30, shape=Xn0.shape[1])\n",
    "  # prior over the variance of the noise\n",
    "  sigma = pm.HalfCauchy('sigma_n', 5)\n",
    "  # linear regression relationship\n",
    "  #linear regression model in matrix form\n",
    "  mu = alpha + pm.math.dot(beta, Xn0.T)\n",
    "  # likelihood, be sure that observed is a 1d vector\n",
    "  like = pm.Normal('like', mu=mu, sigma=sigma, observed=yn0[:,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHBgUe1pcZQQ"
   },
   "source": [
    "##Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfSEdYAUoIDn"
   },
   "source": [
    "### Only Cluster 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgMUwBO7oIDq"
   },
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMY9rDvVoIDq"
   },
   "source": [
    "## Test set performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGmB9BNkoIDr"
   },
   "source": [
    "### PPC on the Test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0GYCpwEM09T"
   },
   "source": [
    "# SUMMARY"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ET5003_Etivity2_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
